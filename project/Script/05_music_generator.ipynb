{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36fe45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"   # disables GPU completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad28fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, Dense, Dropout,\n",
    "    Concatenate, RepeatVector, Flatten\n",
    ")\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67485747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIG ==========\n",
    "DATA_DIR = \"../data/training_data\"\n",
    "ARTIFACT_DIR = \"artifacts\"\n",
    "MODEL_DIR = \"../models\"\n",
    "\n",
    "MOODS = [\"happy\", \"sad\", \"angry\", \"quiet\"]\n",
    "SEQ_LEN = 50\n",
    "\n",
    "NOTE_EMBED_DIM = 128      # reduced for CPU\n",
    "MOOD_EMBED_DIM = 16\n",
    "LSTM_UNITS = 256\n",
    "\n",
    "BATCH_SIZE = 128          # safe for CPU\n",
    "EPOCHS = 3\n",
    "# ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e193d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1602bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: (16716936, 50)\n",
      "Vocabulary size: 128\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{DATA_DIR}/X.pkl\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "\n",
    "with open(f\"{DATA_DIR}/y.pkl\", \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "\n",
    "with open(f\"{DATA_DIR}/mood_labels.pkl\", \"rb\") as f:\n",
    "    moods = pickle.load(f)\n",
    "\n",
    "with open(f\"{ARTIFACT_DIR}/note_to_idx.pkl\", \"rb\") as f:\n",
    "    note_to_idx = pickle.load(f)\n",
    "\n",
    "vocab_size = len(note_to_idx)\n",
    "\n",
    "print(\"Samples:\", X.shape)\n",
    "print(\"Vocabulary size:\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376e6eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 1, 16)                64        ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 16)                   0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 50, 128)              16384     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " repeat_vector (RepeatVecto  (None, 50, 16)               0         ['flatten[0][0]']             \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 50, 144)              0         ['embedding[0][0]',           \n",
      "                                                                     'repeat_vector[0][0]']       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 256)                  410624    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 256)                  0         ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  32896     ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 459968 (1.75 MB)\n",
      "Trainable params: 459968 (1.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "note_input = Input(shape=(SEQ_LEN,))\n",
    "mood_input = Input(shape=(1,))\n",
    "\n",
    "note_emb = Embedding(vocab_size, NOTE_EMBED_DIM)(note_input)\n",
    "mood_emb = Embedding(len(MOODS), MOOD_EMBED_DIM)(mood_input)\n",
    "\n",
    "mood_emb_flat = Flatten()(mood_emb)\n",
    "mood_rep = RepeatVector(SEQ_LEN)(mood_emb_flat)\n",
    "\n",
    "x = Concatenate()([note_emb, mood_rep])\n",
    "x = LSTM(LSTM_UNITS)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "output = Dense(vocab_size, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model([note_input, mood_input], output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\"\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f943d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "130602/130602 [==============================] - 19638s 150ms/step - loss: 1.8816\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\Ai_Music_Composer\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130602/130602 [==============================] - 32377s 248ms/step - loss: 1.7787\n",
      "Epoch 3/3\n",
      "130602/130602 [==============================] - 34179s 262ms/step - loss: 1.7555\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=f\"{MODEL_DIR}/music_generator_cpu.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"loss\"\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [X, moods],\n",
    "    y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[checkpoint, early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b684310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU-trained music generator saved\n"
     ]
    }
   ],
   "source": [
    "model.save(f\"{MODEL_DIR}/music_generator.h5\")\n",
    "print(\"CPU-trained music generator saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
